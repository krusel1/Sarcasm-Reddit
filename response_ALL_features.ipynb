{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurenkruse/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/laurenkruse/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/laurenkruse/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: image not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-248cef829238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sarcasm/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>funct</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>present</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>certain</th>\n",
       "      <th>ppron</th>\n",
       "      <th>you</th>\n",
       "      <th>social</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>conj</th>\n",
       "      <th>tentat</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>discrep</th>\n",
       "      <th>past</th>\n",
       "      <th>motion</th>\n",
       "      <th>relativ</th>\n",
       "      <th>space</th>\n",
       "      <th>preps</th>\n",
       "      <th>incl</th>\n",
       "      <th>adverb</th>\n",
       "      <th>insight</th>\n",
       "      <th>shehe</th>\n",
       "      <th>achieve</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>they</th>\n",
       "      <th>cause</th>\n",
       "      <th>article</th>\n",
       "      <th>money</th>\n",
       "      <th>work</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>swear</th>\n",
       "      <th>time</th>\n",
       "      <th>negate</th>\n",
       "      <th>leisure</th>\n",
       "      <th>death</th>\n",
       "      <th>number</th>\n",
       "      <th>see</th>\n",
       "      <th>sad</th>\n",
       "      <th>quant</th>\n",
       "      <th>anx</th>\n",
       "      <th>assent</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>filler</th>\n",
       "      <th>body</th>\n",
       "      <th>friend</th>\n",
       "      <th>sexual</th>\n",
       "      <th>we</th>\n",
       "      <th>home</th>\n",
       "      <th>feel</th>\n",
       "      <th>inhib</th>\n",
       "      <th>humans</th>\n",
       "      <th>i</th>\n",
       "      <th>family</th>\n",
       "      <th>relig</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ingest</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.167658</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.87530</td>\n",
       "      <td>I don't get this .. obviously you do car...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>6.222500</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.11985</td>\n",
       "      <td>trying to protest about . Talking about hi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>3.713333</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>['trying', 'to', 'protest', 'about', '.', 'Tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.27130</td>\n",
       "      <td>He makes an insane about of money from t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.246667</td>\n",
       "      <td>5.223333</td>\n",
       "      <td>5.426667</td>\n",
       "      <td>['He', 'makes', 'an', 'insane', 'about', 'of',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.243056</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.24470</td>\n",
       "      <td>Meanwhile Trump won't even release his SAT...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.661111</td>\n",
       "      <td>4.428889</td>\n",
       "      <td>5.907778</td>\n",
       "      <td>['Meanwhile', 'Trump', 'wo', \"n't\", 'even', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>5.575758</td>\n",
       "      <td>0.168962</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.83525</td>\n",
       "      <td>Pretty Sure the Anti-Lincoln Crowd Claimed...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>['Pretty', 'Sure', 'the', 'Anti-Lincoln', 'Cro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verb  funct  auxverb  present  pronoun  ipron  cogmech  certain  ppron  \\\n",
       "0     7     13        3        5        5      1        6        1      4   \n",
       "1     2     11        1        2        5      1        3        0      4   \n",
       "2     1      5        0        1        0      0        1        0      0   \n",
       "3     3      9        1        0        4      0        2        1      4   \n",
       "4     0      5        0        0        0      0        0        0      0   \n",
       "\n",
       "   you  social  affect  posemo  conj  tentat  excl  future  discrep  past  \\\n",
       "0    3       4       2       2     2       1     1       1        1     1   \n",
       "1    0       4       1       0     2       0     0       0        0     0   \n",
       "2    0       0       0       0     0       0     0       0        0     0   \n",
       "3    0       5       1       0     1       0     0       0        0     3   \n",
       "4    0       0       0       0     0       0     0       0        0     0   \n",
       "\n",
       "   motion  relativ  space  preps  incl  adverb  insight  shehe  achieve  \\\n",
       "0       1        2      1      2     2       1        1      1        0   \n",
       "1       0        0      0      3     2       2        0      2        1   \n",
       "2       0        0      0      3     0       1        0      0        0   \n",
       "3       0        1      0      0     1       2        0      3        0   \n",
       "4       0        2      2      2     0       1        0      0        0   \n",
       "\n",
       "   negemo  anger  they  cause  article  money  work  percept  hear  swear  \\\n",
       "0       0      0     0      0        0      0     0        0     0      0   \n",
       "1       1      1     2      1        0      0     0        0     0      0   \n",
       "2       0      0     0      1        2      1     0        0     0      0   \n",
       "3       1      1     1      0        1      0     3        1     1      1   \n",
       "4       0      0     0      0        2      0     0        0     0      0   \n",
       "\n",
       "   time  negate  leisure  death  number  see  sad  quant  anx  assent  bio  \\\n",
       "0     0       0        0      0       0    0    0      0    0       0    0   \n",
       "1     0       0        0      0       0    0    0      0    0       0    0   \n",
       "2     0       0        0      0       0    0    0      0    0       0    0   \n",
       "3     1       0        0      0       0    0    0      0    0       0    0   \n",
       "4     0       0        0      0       0    0    0      0    0       0    0   \n",
       "\n",
       "   health  filler  body  friend  sexual  we  home  feel  inhib  humans  i  \\\n",
       "0       0       0     0       0       0   0     0     0      0       0  0   \n",
       "1       0       0     0       0       0   0     0     0      0       0  0   \n",
       "2       0       0     0       0       0   0     0     0      0       0  0   \n",
       "3       0       0     0       0       0   0     0     0      0       0  0   \n",
       "4       0       0     0       0       0   0     0     0      0       0  0   \n",
       "\n",
       "   family  relig  nonfl  ingest    label  noun_count_percent  \\\n",
       "0       0      0      0       0  SARCASM            0.310345   \n",
       "1       0      0      0       0  SARCASM            0.250000   \n",
       "2       0      0      0       0  SARCASM            0.055556   \n",
       "3       0      0      0       0  SARCASM            0.208333   \n",
       "4       0      0      0       0  SARCASM            0.060606   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.034483           0.172414           0.172414    4.862069   \n",
       "1           0.000000           0.000000           0.166667    5.000000   \n",
       "2           0.000000           0.000000           0.055556    5.777778   \n",
       "3           0.041667           0.166667           0.166667    5.833333   \n",
       "4           0.030303           0.030303           0.030303    5.575758   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.167658           0.379310               0.137931      0.204   \n",
       "1      0.208333           0.166667               0.125000      0.000   \n",
       "2      0.320988           0.333333               0.222222      0.000   \n",
       "3      0.243056           0.166667               0.125000      0.000   \n",
       "4      0.168962           0.393939               0.090909      0.193   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0      0.000      0.796         0.87530   \n",
       "1      0.256      0.744         0.11985   \n",
       "2      0.176      0.824         0.27130   \n",
       "3      0.130      0.870         0.24470   \n",
       "4      0.000      0.807         0.83525   \n",
       "\n",
       "                                            response Response_emotion  \\\n",
       "0        I don't get this .. obviously you do car...          sadness   \n",
       "1      trying to protest about . Talking about hi...            anger   \n",
       "2        He makes an insane about of money from t...            anger   \n",
       "3      Meanwhile Trump won't even release his SAT...            anger   \n",
       "4      Pretty Sure the Anti-Lincoln Crowd Claimed...              joy   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0          6.222500          3.695000            5.965000   \n",
       "1          5.190000          3.713333            5.733333   \n",
       "2          5.246667          5.223333            5.426667   \n",
       "3          5.661111          4.428889            5.907778   \n",
       "4          5.000000          5.000000            5.000000   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...  \n",
       "1  ['trying', 'to', 'protest', 'about', '.', 'Tal...  \n",
       "2  ['He', 'makes', 'an', 'insane', 'about', 'of',...  \n",
       "3  ['Meanwhile', 'Trump', 'wo', \"n't\", 'even', 'r...  \n",
       "4  ['Pretty', 'Sure', 'the', 'Anti-Lincoln', 'Cro...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/Desktop/UpdatedSarcasm/liwc_response_train.csv'\n",
    "#csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_Features_train_data'\n",
    "Train_df = pd.read_csv(csv_file)\n",
    "Train_df = Train_df.loc[:, ~Train_df.columns.str.contains('^Unnamed')]\n",
    "# print out the first few rows of data info\n",
    "Train_df.head(5)\n",
    "\n",
    "#These are the most useful features per SHAP \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>relativ</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>adverb</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>excl</th>\n",
       "      <th>leisure</th>\n",
       "      <th>conj</th>\n",
       "      <th>incl</th>\n",
       "      <th>verb</th>\n",
       "      <th>past</th>\n",
       "      <th>social</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>cause</th>\n",
       "      <th>humans</th>\n",
       "      <th>certain</th>\n",
       "      <th>achieve</th>\n",
       "      <th>preps</th>\n",
       "      <th>tentat</th>\n",
       "      <th>space</th>\n",
       "      <th>affect</th>\n",
       "      <th>filler</th>\n",
       "      <th>posemo</th>\n",
       "      <th>present</th>\n",
       "      <th>they</th>\n",
       "      <th>shehe</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>quant</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>article</th>\n",
       "      <th>insight</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "      <th>motion</th>\n",
       "      <th>discrep</th>\n",
       "      <th>assent</th>\n",
       "      <th>inhib</th>\n",
       "      <th>home</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>anx</th>\n",
       "      <th>sad</th>\n",
       "      <th>see</th>\n",
       "      <th>money</th>\n",
       "      <th>negate</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>future</th>\n",
       "      <th>swear</th>\n",
       "      <th>ingest</th>\n",
       "      <th>feel</th>\n",
       "      <th>number</th>\n",
       "      <th>body</th>\n",
       "      <th>relig</th>\n",
       "      <th>family</th>\n",
       "      <th>we</th>\n",
       "      <th>death</th>\n",
       "      <th>friend</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>4.567164</td>\n",
       "      <td>0.068167</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.71005</td>\n",
       "      <td>My 3 year old , that just finished readi...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.671111</td>\n",
       "      <td>4.181667</td>\n",
       "      <td>5.976667</td>\n",
       "      <td>['My', '3', 'year', 'old', ',', 'that', 'just'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.60115</td>\n",
       "      <td>How many verifiable lies has he told now ?...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.442857</td>\n",
       "      <td>3.635714</td>\n",
       "      <td>5.554286</td>\n",
       "      <td>['How', 'many', 'verifiable', 'lies', 'has', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>4.695652</td>\n",
       "      <td>0.204159</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>Maybe Docs just a scrub of a coach ... I...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.236250</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>['Maybe', 'Docs', 'just', 'a', 'scrub', 'of', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.19430</td>\n",
       "      <td>is just a cover up for the real hate insid...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.174000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>5.474000</td>\n",
       "      <td>['is', 'just', 'a', 'cover', 'up', 'for', 'the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.47420</td>\n",
       "      <td>The irony being that he even has to ask ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.795000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>5.697500</td>\n",
       "      <td>['The', 'irony', 'being', 'that', 'he', 'even'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  relativ  funct  pronoun  ipron  adverb  cogmech  excl  leisure  conj  \\\n",
       "0   6.0      6.0   19.0      9.0    5.0     3.0      9.0   2.0      2.0   5.0   \n",
       "1   1.0      1.0    6.0      1.0    0.0     1.0      2.0   0.0      0.0   0.0   \n",
       "2   0.0      0.0    7.0      1.0    1.0     1.0      4.0   1.0      2.0   0.0   \n",
       "3   0.0      4.0    9.0      0.0    0.0     1.0      3.0   1.0      0.0   0.0   \n",
       "4   0.0      0.0    6.0      2.0    1.0     1.0      1.0   0.0      0.0   0.0   \n",
       "\n",
       "   incl  verb  past  social  ppron    i  cause  humans  certain  achieve  \\\n",
       "0   2.0   2.0   1.0     7.0    4.0  1.0    3.0     1.0      1.0      4.0   \n",
       "1   0.0   2.0   1.0     2.0    1.0  0.0    0.0     0.0      2.0      0.0   \n",
       "2   1.0   2.0   0.0     1.0    0.0  0.0    0.0     0.0      0.0      1.0   \n",
       "3   1.0   2.0   0.0     0.0    0.0  0.0    0.0     0.0      1.0      0.0   \n",
       "4   0.0   3.0   0.0     2.0    1.0  0.0    1.0     0.0      0.0      0.0   \n",
       "\n",
       "   preps  tentat  space  affect  filler  posemo  present  they  shehe  negemo  \\\n",
       "0    3.0     1.0    1.0     4.0     1.0     3.0      1.0   2.0    1.0     1.0   \n",
       "1    1.0     0.0    0.0     3.0     0.0     2.0      1.0   0.0    1.0     1.0   \n",
       "2    3.0     0.0    0.0     0.0     0.0     0.0      2.0   0.0    0.0     0.0   \n",
       "3    4.0     0.0    4.0     1.0     0.0     0.0      2.0   0.0    0.0     1.0   \n",
       "4    1.0     0.0    0.0     0.0     0.0     0.0      2.0   0.0    1.0     0.0   \n",
       "\n",
       "   anger  quant  auxverb  article  insight  work  you  motion  discrep  \\\n",
       "0    1.0    0.0      0.0      0.0      0.0   0.0  0.0     0.0      0.0   \n",
       "1    1.0    1.0      1.0      1.0      0.0   0.0  0.0     0.0      0.0   \n",
       "2    0.0    0.0      0.0      2.0      1.0   1.0  0.0     0.0      0.0   \n",
       "3    1.0    0.0      1.0      3.0      0.0   0.0  0.0     0.0      0.0   \n",
       "4    0.0    0.0      2.0      0.0      0.0   0.0  0.0     0.0      0.0   \n",
       "\n",
       "   assent  inhib  home  percept  hear  anx  sad  see  money  negate  bio  \\\n",
       "0     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "1     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "2     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "3     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "4     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "\n",
       "   health  sexual  nonfl  future  swear  ingest  feel  number  body  relig  \\\n",
       "0     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "1     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "2     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "3     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "4     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "\n",
       "   family   we  death  friend        label  noun_count_percent  \\\n",
       "0     0.0  0.0    0.0     0.0  NOT_SARCASM            0.134328   \n",
       "1     0.0  0.0    0.0     0.0      SARCASM            0.181818   \n",
       "2     0.0  0.0    0.0     0.0      SARCASM            0.130435   \n",
       "3     0.0  0.0    0.0     0.0  NOT_SARCASM            0.045455   \n",
       "4     0.0  0.0    0.0     0.0  NOT_SARCASM            0.200000   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.104478           0.089552           0.074627    4.567164   \n",
       "1           0.136364           0.045455           0.090909    4.818182   \n",
       "2           0.043478           0.043478           0.043478    4.695652   \n",
       "3           0.090909           0.045455           0.000000    4.272727   \n",
       "4           0.000000           0.133333           0.066667    4.200000   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.068167           0.283582               0.074627      0.147   \n",
       "1      0.219008           0.363636               0.090909      0.215   \n",
       "2      0.204159           0.260870               0.173913      0.000   \n",
       "3      0.194215           0.318182               0.181818      0.000   \n",
       "4      0.280000           0.266667               0.200000      0.000   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0      0.134      0.719         0.71005   \n",
       "1      0.131      0.654         0.60115   \n",
       "2      0.000      1.000         0.50000   \n",
       "3      0.200      0.800         0.19430   \n",
       "4      0.091      0.909         0.47420   \n",
       "\n",
       "                                            response Response_emotion  \\\n",
       "0        My 3 year old , that just finished readi...              joy   \n",
       "1      How many verifiable lies has he told now ?...              joy   \n",
       "2        Maybe Docs just a scrub of a coach ... I...            anger   \n",
       "3      is just a cover up for the real hate insid...            anger   \n",
       "4        The irony being that he even has to ask ...            anger   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0          5.671111          4.181667            5.976667   \n",
       "1          5.442857          3.635714            5.554286   \n",
       "2          5.236250          4.210000            5.270000   \n",
       "3          5.174000          4.290000            5.474000   \n",
       "4          5.795000          3.630000            5.697500   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['My', '3', 'year', 'old', ',', 'that', 'just'...  \n",
       "1  ['How', 'many', 'verifiable', 'lies', 'has', '...  \n",
       "2  ['Maybe', 'Docs', 'just', 'a', 'scrub', 'of', ...  \n",
       "3  ['is', 'just', 'a', 'cover', 'up', 'for', 'the...  \n",
       "4  ['The', 'irony', 'being', 'that', 'he', 'even'...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/Desktop/UpdatedSarcasm/Reddit_Test2Contexts.csv'\n",
    "#csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_Features_test_data'\n",
    "Test_df = pd.read_csv(csv_file)\n",
    "Test_df = Test_df.loc[:, ~Test_df.columns.str.contains('^Unnamed')]\n",
    "# print out the first few rows of data info\n",
    "Test_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train_df\n",
    "\n",
    "X_test= Test_df\n",
    "\n",
    "y_train= Train_df['label']\n",
    "\n",
    "y_test = Test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test['Response_emotion'] = X_test['Response_emotion'].astype('category').cat.codes\n",
    "\n",
    "X_train['Response_emotion'] = X_train['Response_emotion'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>relativ</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>adverb</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>excl</th>\n",
       "      <th>leisure</th>\n",
       "      <th>conj</th>\n",
       "      <th>incl</th>\n",
       "      <th>verb</th>\n",
       "      <th>past</th>\n",
       "      <th>social</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>cause</th>\n",
       "      <th>humans</th>\n",
       "      <th>certain</th>\n",
       "      <th>achieve</th>\n",
       "      <th>preps</th>\n",
       "      <th>tentat</th>\n",
       "      <th>space</th>\n",
       "      <th>affect</th>\n",
       "      <th>filler</th>\n",
       "      <th>posemo</th>\n",
       "      <th>present</th>\n",
       "      <th>they</th>\n",
       "      <th>shehe</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>quant</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>article</th>\n",
       "      <th>insight</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "      <th>motion</th>\n",
       "      <th>discrep</th>\n",
       "      <th>assent</th>\n",
       "      <th>inhib</th>\n",
       "      <th>home</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>anx</th>\n",
       "      <th>sad</th>\n",
       "      <th>see</th>\n",
       "      <th>money</th>\n",
       "      <th>negate</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>future</th>\n",
       "      <th>swear</th>\n",
       "      <th>ingest</th>\n",
       "      <th>feel</th>\n",
       "      <th>number</th>\n",
       "      <th>body</th>\n",
       "      <th>relig</th>\n",
       "      <th>family</th>\n",
       "      <th>we</th>\n",
       "      <th>death</th>\n",
       "      <th>friend</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>4.567164</td>\n",
       "      <td>0.068167</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.71005</td>\n",
       "      <td>My 3 year old , that just finished readi...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.671111</td>\n",
       "      <td>4.181667</td>\n",
       "      <td>5.976667</td>\n",
       "      <td>['My', '3', 'year', 'old', ',', 'that', 'just'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  relativ  funct  pronoun  ipron  adverb  cogmech  excl  leisure  conj  \\\n",
       "0   6.0      6.0   19.0      9.0    5.0     3.0      9.0   2.0      2.0   5.0   \n",
       "\n",
       "   incl  verb  past  social  ppron    i  cause  humans  certain  achieve  \\\n",
       "0   2.0   2.0   1.0     7.0    4.0  1.0    3.0     1.0      1.0      4.0   \n",
       "\n",
       "   preps  tentat  space  affect  filler  posemo  present  they  shehe  negemo  \\\n",
       "0    3.0     1.0    1.0     4.0     1.0     3.0      1.0   2.0    1.0     1.0   \n",
       "\n",
       "   anger  quant  auxverb  article  insight  work  you  motion  discrep  \\\n",
       "0    1.0    0.0      0.0      0.0      0.0   0.0  0.0     0.0      0.0   \n",
       "\n",
       "   assent  inhib  home  percept  hear  anx  sad  see  money  negate  bio  \\\n",
       "0     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "\n",
       "   health  sexual  nonfl  future  swear  ingest  feel  number  body  relig  \\\n",
       "0     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "\n",
       "   family   we  death  friend        label  noun_count_percent  \\\n",
       "0     0.0  0.0    0.0     0.0  NOT_SARCASM            0.134328   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.104478           0.089552           0.074627    4.567164   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.068167           0.283582               0.074627      0.147   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0      0.134      0.719         0.71005   \n",
       "\n",
       "                                            response  Response_emotion  \\\n",
       "0        My 3 year old , that just finished readi...                 2   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0          5.671111          4.181667            5.976667   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['My', '3', 'year', 'old', ',', 'that', 'just'...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>funct</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>present</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>certain</th>\n",
       "      <th>ppron</th>\n",
       "      <th>you</th>\n",
       "      <th>social</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>conj</th>\n",
       "      <th>tentat</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>discrep</th>\n",
       "      <th>past</th>\n",
       "      <th>motion</th>\n",
       "      <th>relativ</th>\n",
       "      <th>space</th>\n",
       "      <th>preps</th>\n",
       "      <th>incl</th>\n",
       "      <th>adverb</th>\n",
       "      <th>insight</th>\n",
       "      <th>shehe</th>\n",
       "      <th>achieve</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>they</th>\n",
       "      <th>cause</th>\n",
       "      <th>article</th>\n",
       "      <th>money</th>\n",
       "      <th>work</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>swear</th>\n",
       "      <th>time</th>\n",
       "      <th>negate</th>\n",
       "      <th>leisure</th>\n",
       "      <th>death</th>\n",
       "      <th>number</th>\n",
       "      <th>see</th>\n",
       "      <th>sad</th>\n",
       "      <th>quant</th>\n",
       "      <th>anx</th>\n",
       "      <th>assent</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>filler</th>\n",
       "      <th>body</th>\n",
       "      <th>friend</th>\n",
       "      <th>sexual</th>\n",
       "      <th>we</th>\n",
       "      <th>home</th>\n",
       "      <th>feel</th>\n",
       "      <th>inhib</th>\n",
       "      <th>humans</th>\n",
       "      <th>i</th>\n",
       "      <th>family</th>\n",
       "      <th>relig</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ingest</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.167658</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>I don't get this .. obviously you do car...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.2225</td>\n",
       "      <td>3.695</td>\n",
       "      <td>5.965</td>\n",
       "      <td>['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verb  funct  auxverb  present  pronoun  ipron  cogmech  certain  ppron  \\\n",
       "0     7     13        3        5        5      1        6        1      4   \n",
       "\n",
       "   you  social  affect  posemo  conj  tentat  excl  future  discrep  past  \\\n",
       "0    3       4       2       2     2       1     1       1        1     1   \n",
       "\n",
       "   motion  relativ  space  preps  incl  adverb  insight  shehe  achieve  \\\n",
       "0       1        2      1      2     2       1        1      1        0   \n",
       "\n",
       "   negemo  anger  they  cause  article  money  work  percept  hear  swear  \\\n",
       "0       0      0     0      0        0      0     0        0     0      0   \n",
       "\n",
       "   time  negate  leisure  death  number  see  sad  quant  anx  assent  bio  \\\n",
       "0     0       0        0      0       0    0    0      0    0       0    0   \n",
       "\n",
       "   health  filler  body  friend  sexual  we  home  feel  inhib  humans  i  \\\n",
       "0       0       0     0       0       0   0     0     0      0       0  0   \n",
       "\n",
       "   family  relig  nonfl  ingest    label  noun_count_percent  \\\n",
       "0       0      0      0       0  SARCASM            0.310345   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.034483           0.172414           0.172414    4.862069   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.167658            0.37931               0.137931      0.204   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0        0.0      0.796          0.8753   \n",
       "\n",
       "                                            response  Response_emotion  \\\n",
       "0        I don't get this .. obviously you do car...                 4   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0            6.2225             3.695               5.965   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['tokenized_text','label','response'], axis=1)\n",
    "X_test = X_test.drop(['tokenized_text','label','response'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "# fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, y_test),metrics.precision_score(predictions, y_test),metrics.recall_score(predictions, y_test),metrics.f1_score(predictions, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random Forest:  A: 0.59 P: 0.56 R: 0.6 F1: 0.52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy, precision, recall,fl  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), X_train, y_train, X_test)\n",
    "print (\"random Forest: \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
